---
title: "Analysis_LoL"
author: "Marshall Gallt"
date: "2/28/2022"
output: github_document
---

```{r setup, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(lubridate)
library(corrplot)
library(Hmisc)
library(caret)

```


# Introduction

League of Legends is a popular PC game. Teams all around the world compete with
the hopes of making it to Worlds. Riot has released data for each player of each
professional game of the 2022 season thus far. In this project I will perform 
logistic regression in R on the `2022 Match Data` found on Oracle Elixir's 
[downloads page](https://oracleselixir.com/tools/downloads).
`2022_LoL_esports_match_data_from_OraclesElixir_20220228.csv`
I imported the data on February 28th, 2022. This data has been updated since.


# Research Questions

In this logistic regression a number of questions could be posed. Examples
include, what indicates a winning score for each role, when is gold income the
most important, what objectives are the most decisive, how do the teams and
leagues differentiate in strategy.

# Data

First, a quick view of our data.


```{r data, warning=FALSE}

Lol_match_data_2022 <- 
  read_csv("2022_LoL_esports_match_data_from_OraclesElixir_20220228.csv")

Lol_match_data_2022

```

The data we have available is quite large and detailed. So I will be reducing 
the data to; key variables, the "LCS"(North American) `league`, and the entire 
teams stats as valued as "team" for the `position` variable.

```{r reduce, warning=FALSE}

LCS_matches <- Lol_match_data_2022 %>%
  filter(league == "LCS",
         position == "team") %>%
  subset(select = c('gameid',
                    'side',
                    'gamelength',
                    'result',
                    'firstblood',
                    'team kpm',
                    'firstdragon',
                    'dragons',
                    'firstbaron',
                    'barons',
                    'firsttower',
                    'towers',
                    'firstmidtower',
                    'firsttothreetowers',
                    'inhibitors',
                    'vspm',
                    'earned gpm',
                    'cspm')) %>%
  rename(earned_gpm = `earned gpm`,
         team_kpm = `team kpm`)

LCS_matches$result <- LCS_matches$result == TRUE

LCS_matches

```

Variable | Type | Description
---------|------|------------
gameid | Character | Game identification (two teams)
side | Categorical | Side of the map given to team (Red or Blue)
gamelength | Numeric | Length of game in seconds
result | Binary | Win = 1, lose = 0
team_kpm | Numeric | Team's kills per minute
firstdragon | Binary | True if team killed first dragon
dragons | Numeric | Number of dragons killed by team
firstbaron | Binary | True if team killed first baron
barons | Numeric | Numer of dragons killed by team
firsttower | Binary | True if team destroyed first tower
towers | Numeric | Number of towers destroyed by team
firstmidtower | Binary | True if team destroyed the first mid tower
firsttothreetowers | Binary | True if team was first to destroy three towers
inhibitors | Numeric | Number of inhibitors destroyed by team
vspm | Numeric | Team's vision score per minute
earned_gpm | Numeric | Team's gold earned per minute
cspm | Numeric | Team's creep score per minute


# Exploratory Data Analysis

First, we conduct an exploratory data analysis.



## Numerical Summaries

```{r summary}
summary(LCS_matches)

```


## Graphical Summaries

### Pearson corrolation plot

Here we create a correlation that visualizes the linear correlation between each
pair of variables and use `order = 'AOE'` to organize our variables based off
their eigenvectors.
```{r corr_matrix, warning=FALSE}

LCS_matches %>%
  data.matrix() %>%
  cor() %>%
  corrplot(is.corr = FALSE, order = 'AOE')

  
```


### Checking data for relationships

To check the shape of the data columns to see if they might be well fit by any
particular random variables, and if there are any outliers, we create whisker 
plots of each variable as applicable. 

```{r data_shapes}

par(mar=c(.5,.5,.5,.5))

num_LCS <- LCS_matches %>%
  select_if(is.numeric)

par(mfrow = c(2,5))

for(i in 1:10) {
   boxplot(num_LCS[,i],
           main = names(num_LCS)[i])
}

```

These reveal that to our luck, there aren't any serious 
outliers and that also specific pieces of data seem to fit specific 
distributions such as
Normal - gamelength, vspm, cspm
Pareto/Exponential - inhibitors
Bivariate Normal - towers

This provides us some insight onto the nature of how these might affect game 
outcomes and also how they may relate to one another

``` {r pairs, warning= FALSE}

cols <- character(nrow(LCS_matches))

cols[] <- "black"

cols[LCS_matches$result == TRUE] <- "red"

pairs(num_LCS,
      col=cols,
      order = "FPC")

```


```{r linear_model}

LCS_model = lm(LCS_matches$result ~ ., data = num_LCS)
summary(LCS_model)

```
### Regressions of strongly correlated variables

Here we will do some regression modeling of `result` vs `towers`,`inhibitors`, 
`earned_gpm`, and `team_kpm`. I've chosen these variables because they all
strongly correlate with each other and display similar correlation patterns with
the other variables.

```{r towers_regression }

input <- LCS_matches[,c("result", "towers")]

model_towers <- glm(formula = result ~ towers, data = input, family = binomial)

summary(model_towers)

tower_regression <- data.frame(towers=seq(min(LCS_matches$towers),
                                          max(LCS_matches$towers),
                                          len=500))

tower_regression$result = predict(model_towers, 
                                  tower_regression, 
                                  type="response")

plot(result ~ towers,
     data=LCS_matches,
     col="steelblue")

lines(result ~ towers,
      tower_regression,
      lwd=2)

```

```{r baron_regression }

input <- LCS_matches[,c("result", "barons")]

model_barons <- glm(formula = result ~ barons,
                        data = input,
                        family = binomial)

summary(model_barons)

baron_regression <- data.frame(barons=seq(min(LCS_matches$barons),
                                                  max(LCS_matches$barons),
                                                  len=500))

baron_regression$result = predict(model_barons,
                                      baron_regression,
                                      type="response")

plot(result ~ barons,
     data = LCS_matches,
     col = "steelblue")

lines(result ~ barons,
      baron_regression,
      lwd = 2)

```

```{r dragon_regression }

input <- LCS_matches[,c("result", "dragons")]

model_dragons <- glm(formula = result ~ dragons,
                        data = input,
                        family = binomial)

summary(model_dragons)

dragon_regression <- data.frame(dragons = seq(min(LCS_matches$dragons),
                                                  max(LCS_matches$dragons),
                                                  len = 500))

dragon_regression$result = predict(model_dragons,
                                      dragon_regression,
                                      type = "response")

plot(result ~ dragons,
     data = LCS_matches,
     col = "steelblue")

lines(result ~ dragons,
      dragon_regression,
      lwd = 2)

```

```{r tkpm_regression }

input <- LCS_matches[,c("result", "team_kpm")]

model_tkpm <- glm(formula = result ~ team_kpm,
                        data = input,
                        family = binomial)

summary(model_tkpm)

tkpm_regression <- data.frame(team_kpm = seq(min(LCS_matches$team_kpm),
                                                  max(LCS_matches$team_kpm),
                                                  len = 500))

tkpm_regression$result = predict(model_tkpm,
                                 tkpm_regression,
                                 type = "response")

plot(result ~ team_kpm,
     data = LCS_matches,
     col = "steelblue")

lines(result ~ team_kpm,
      tkpm_regression,
      lwd = 2)

```




# Data Cleaning and Wrangling

As seen in our `summary` of `LCS_matches`, after reducing our dataset we no 
longer have any missing values! There's one other thing we want to consider in
data cleaning though, outliers. From our whisker plots we do see outliers.
However, I don't believe that any of them are outlandish enough to warrant
removal. So it appears there's no cleaning to do.

I'll note that I've already made a few changes to the data in pursuit of peace;
I've changed the variables names of `team kpm` and `earned gpm` to `team_kpm` 
and `earned_gpm`. As well as converted `result` to logical values. This was
simple due to the cleanliness of our data.

I would further my data wrangling by combining and binning some of my strongly
correlated variables.


```{r wrangle}

new_model = lm(LCS_matches$result ~ . - towers, data = LCS_matches)

summary(new_model)$r.squared

new_model = lm(LCS_matches$result ~ . - barons, data = LCS_matches)

summary(new_model)$r.squared

new_model = lm(LCS_matches$result ~ . - dragons, data = LCS_matches)

summary(new_model)$r.squared

new_model = lm(LCS_matches$result ~ . - team_kpm, data = LCS_matches)

summary(new_model)$r.squared

```

I do believe these are all worth keeping but will also perform logistic
regression with the indicator variable as `barons`,`dragons`, and `team_kpm`.

# Data Analysis



# Hypotheses



# Modeling



# Conclusion




